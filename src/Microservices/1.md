
**MICROSERVICES**

DISTRIBUTED TRANSACTIONS

- 




### Monitoring  Spring boot Applications on Production


**Q) How do you monitor your spring boot application on prod?**


Tools and Techniques for Monitoring

**Actuator Endpoints:**

- **Spring Boot Actuator**: Use Spring Boot Actuator to expose various endpoints that provide information about the application's health, metrics, environment, and more. Key endpoints include `/health` , `/metrics` , `/info` , and `/env` .


**Application Performance Monitoring (APM) Tools:**

- **Prometheus and Grafana**:
    - **Prometheus**: For collecting and storing metrics.
    - **Grafana**: For visualizing metrics and creating dashboards.
    - **Integration**: Integrate Spring Boot with Prometheus using the `micrometer`  library, which can export metrics from Actuator to Prometheus.
- **New Relic, Dynatrace, Datadog, or AppDynamics**: These are comprehensive APM tools that offer real-time monitoring, detailed performance metrics, distributed tracing, and alerting capabilities.


**Logging:**

- **Log Aggregation**: Use tools like ELK stack (Elasticsearch, Logstash, and Kibana) or Fluentd with Elasticsearch and Kibana to aggregate logs from multiple instances of your application.
- **Structured Logging**: Implement structured logging (e.g., JSON format) to make logs easier to search and analyze.


**Distributed Tracing:**

- **Jaeger or Zipkin**: Implement distributed tracing to trace requests as they propagate through different microservices. This helps in identifying performance bottlenecks and latency issues.
- **Spring Cloud Sleuth**: Use Spring Cloud Sleuth to add trace and span IDs to logs automatically, making it easier to trace the flow of requests.


**Alerting:**

- **Prometheus Alertmanager**: Set up alerting rules in Prometheus and use Alertmanager to handle alerts, sending notifications via email, Slack, PagerDuty, etc.
- **Third-Party APM Alerts**: Use built-in alerting features in APM tools like New Relic, Datadog, or Dynatrace to get notified about performance issues, errors, and downtime.
### 
### Microservices IQ


**Q) What is service discovery? Why do you need multiple Eurekas?**
A) Service discovery is the process by which microservices locate each other dynamically at runtime instead of relying on static configuration.

Multiple Eureka servers are often used for high availability and fault tolerance. They work in a cluster to provide redundancy, ensuring that even if one Eureka server goes down, the others can continue to handle service discovery requests.



**Q) What is circuit breaker DP?**
A) The Circuit Breaker Design Pattern is used to detect failures and encapsulate the logic of preventing a failure from constantly recurring during maintenance, temporary external system failure, or unexpected system difficulties. It acts as a proxy that monitors for failures and opens the circuit if the failure threshold is reached, preventing further calls to the failing service until it recovers.



**Q) How do you handle transactions across multiple microservices?**
A) Handling transactions across multiple microservices can be challenging. We typically use the **Saga** pattern for distributed transactions.

This involves breaking down a transaction into a series of smaller transactiorns that are managed individually by each service. There are two types of Saga implementations: choreography-based and orchestration-based. In the former, services communicate through events, while in the latter, a central coordinator manages the transaction flow.



**Q) How do microservices communicate with each other?**
A) Microservices can communicate with each other synchronously via REST or gRPC and asynchronously using message brokers like Kafka or RabbitMQ.

Synchronous communication is straightforward but can lead to tight coupling and latency issues.

Asynchronous communication decouples services and enhances scalability but adds complexity to the system.



### Kafka
**Q) Explain the architecture of Kafka.**
A) Kafka is a distributed streaming platform with a robust architecture comprising several key components:

- **Producers**: Applications that publish messages to Kafka topics.
- **Brokers**: Kafka servers that store and manage the messages.
- **Topics**: Categories to which messages are sent by producers.
- **Consumers**: Applications that subscribe to topics to consume messages.
- **Zookeeper**: Manages and coordinates Kafka brokers and maintains configuration information and leader election.
- **Partitions**: Topics are divided into partitions, which are distributed across brokers for scalability and fault tolerance.


**Q) How did you implement Kafka in your project?**
A) In our project, Kafka was implemented to handle real-time data streaming. Producers published data to Kafka topics, which were partitioned for scalability. Consumers subscribed to these topics to process the data. We used Kafka Streams API for processing and transforming the streams. Zookeeper was used for broker management and coordination.



**Q) What is Zookeeper in Kafka? Can Kafka be used without Zookeeper?**
A) Zookeeper is used in Kafka for managing brokers, maintaining metadata about topics and partitions, and handling leader election for partitions.

Kafka 2.8.0 introduced an option to run without Zookeeper by using a new metadata quorum mechanism called KRaft (Kafka Raft).



**Q) What do you mean by ISR in Kafka environment?**
A) ISR (In-Sync Replica) refers to the set of replicas that are fully caught up with the leader’s data. These replicas are essential for ensuring data durability and consistency. If a leader fails, one of the in-sync replicas can be promoted to the new leader.



**Q) What is consumer lag?**
A) Consumer lag is the difference between the latest offset of a partition and the offset of the consumer's last processed message. It indicates how much data is yet to be processed by the consumer. Monitoring lag helps ensure consumers are keeping up with the producers.



**Q) What is marking the offset as soon as you read the message from Kafka broker?**
A) Marking the offset immediately upon reading a message ensures that the message is acknowledged and committed quickly. However, it can lead to message loss if the consumer fails before processing the message. Typically, offsets are committed after processing the message to ensure reliability.



### REST API


**Q) How did you implement synchronous communication between microservices?**
A) Synchronous communication between microservices was implemented using RESTful APIs. We used HTTP/HTTPS protocols with standardized request/response formats like JSON. Tools like Spring RestTemplate or WebClient were used for making API calls.



**Q) You have implemented some REST endpoints for CRUD functionality, how will you share your contract with clients/other teams?**
A) The API contract was shared using Swagger (OpenAPI) documentation. We annotated our REST endpoints with Swagger annotations, generating interactive API documentation that could be accessed via a web interface. This documentation included details about endpoints, request/response formats, parameters, and authentication requirements.



### Spring Security


**Q) How did you implement security end to end?**
A) End-to-end security was implemented using Spring Security.

**Authentication **was handled using OAuth2 and JWT tokens for stateless session management.

Role-based access control (RBAC) was used for **authorization**, ensuring that users had appropriate permissions for various endpoints.

We also implemented **security **measures like CSRF protection, XSS prevention, and HTTPS enforcement.



Steps used

### Step 1: Set Up Okta


1. **Create an Okta Account**: Start by signing up for a free developer account on Okta's website.
2. **Create an Application**: Once logged in, create a new application in the Okta dashboard. Choose "Single-Page App" since we are using Angular.
3. **Configuration**: Note down important details like the **Client ID and Issuer URL **provided by Okta. These will be used in both your Angular app and Spring Boot backend.


### Step 2: Configure Angular Frontend


- **Install Okta Libraries**: Use npm (Node Package Manager) to install Okta's libraries that will help manage authentication.
```
npm install @okta/okta-auth-js @okta/okta-angular
```
- **Setup Okta Configuration**: Configure your Angular application to use Okta, specifying the Client ID and Issuer URL from the Okta dashboard.


- **Routing and Guards**: Update your application routing to handle protected routes, which will require users to be authenticated to access certain parts of the app.


- **Login Functionality**: Add a login button or mechanism in your Angular app that redirects users to Okta for authentication.


### Step 3: Configure Spring Boot Backend


- **Add Dependencies**: Include necessary dependencies in your Spring Boot project to support JWT (JSON Web Token) authentication.


```
<dependency>
 
  <groupId>org.springframework.boot</groupId>
 
  <artifactId>spring-boot-starter-security</artifactId>
 
</dependency>
 
<dependency>
 
  <groupId>org.springframework.boot</groupId>
 
  <artifactId>spring-boot-starter-oauth2-resource-server</artifactId>
 
</dependency>
 
<dependency>
 
  <groupId>com.okta.spring</groupId>
 
  <artifactId>okta-spring-boot-starter</artifactId>
 
  <version>2.1.6</version>
 
</dependency> 
```


- **Security Configuration**: Set up security configurations in your Spring Boot application to ensure that it validates JWT tokens received from Okta.


```
@Configuration
public class SecurityConfig extends WebSecurityConfigurerAdapter {

    @Override
    protected void configure(HttpSecurity http) throws Exception {
        http
            .authorizeRequests()
            .antMatchers("/api/public").permitAll()
            .anyRequest().authenticated()
            .and()
            .oauth2ResourceServer().jwt();
    }
}

```
- **Application Properties**: Configure your application properties to include details like the Issuer URL and Client ID from Okta.
```
okta.oauth2.issuer=https://{yourOktaDomain}/oauth2/default
okta.oauth2.client-id={yourClientId}
spring.security.oauth2.resourceserver.jwt.issuer-uri=https://{yourOktaDomain}/oauth2/default

```
- **Protected Endpoints**: Create endpoints in your Spring Boot application that will be accessible only to authenticated users.
```
@RestController
@RequestMapping("/api")
public class ApiController {

    @GetMapping("/public")
    public String publicEndpoint() {
        return "This is a public endpoint";
    }

    @GetMapping("/protected")
    public String protectedEndpoint() {
        return "This is a protected endpoint";
    }
}

```


### Step 4: Integrate Frontend with Backend


- **Authentication Flow**: When a user tries to access a protected resource, they are redirected to Okta to log in.
```
import { HttpClient, HttpHeaders } from '@angular/common/http';
import { OktaAuthService } from '@okta/okta-angular';

constructor(private http: HttpClient, private oktaAuth: OktaAuthService) { }

async getProtectedData() {
  const accessToken = await this.oktaAuth.getAccessToken();
  const headers = new HttpHeaders().set('Authorization', 'Bearer ' + accessToken);
  return this.http.get('/api/protected', { headers }).toPromise();
}
```
- **Access Token**: After successful login, Okta provides an access token.
- **Make Authenticated Requests**: Use this access token in your Angular application to make requests to your Spring Boot backend. The backend will validate this token to ensure the request is from an authenticated user.
### Summary
1. **Okta Setup**: Create and configure an Okta application to manage user authentication.
2. **Angular Configuration**: Set up your Angular frontend to use Okta for user login and secure certain routes.
3. **Spring Boot Configuration**: Configure your Spring Boot backend to validate JWT tokens issued by Okta and protect certain endpoints.
4. **Integration**: Ensure that your Angular frontend and Spring Boot backend communicate securely using the access tokens provided by Okta after user authentication.




### ORM - SQL/NoSQL


**Q) Which ORM framework have you used?**
A) I have used Hibernate as the ORM framework for SQL databases. For NoSQL databases, I have used Spring Data MongoDB.



**Q) What type of database have you used? SQL or NoSQL and why?**
A) Both types of databases were used depending on the use case.

**SQL databases** (like MySQL and PostgreSQL) were used for transactional data requiring ACID properties and complex queries.

**NoSQL databases** (like MongoDB and Cassandra) were used for handling large volumes of unstructured data, providing high scalability and performance.



### Docker


**Q) Why Docker?**
A) Docker was used to containerize applications, providing a consistent environment across development, testing, and production. It simplifies dependency management, enhances scalability, and isolates applications, making it easier to manage and deploy microservices.



**Q) Docker Commands**
A) Some commonly used Docker commands include:

- `docker build` : Build an image from a Dockerfile.
- `docker run` : Run a container from an image.
- `docker ps` : List running containers.
- `docker stop` : Stop a running container.
- `docker rm` : Remove a container.
- `docker rmi` : Remove an image.


**Q) Explain Docker file**

```
# Use an official OpenJDK runtime as a parent image
# This line specifies the base image that the Docker container will use.
**FROM openjdk:17-jdk-slim**

# Set the working directory in the container
# This sets the working directory inside the Docker container to /app.
**WORKDIR /app**

# Copy the application's jar file to the container
# This copies the Spring Boot application’s jar file from the target directory on your local machine to the /app directory inside the Docker container
**COPY target/my-springboot-app.jar /app/my-springboot-app.jar

**# This exposes port 8080 on the Docker container, which is typically the port a Spring Boot application runs on.
**EXPOSE 8080**

# Run the jar file
# This specifies the command to run the Spring Boot application when the container starts.
**ENTRYPOINT ["java", "-jar", "/app/my-springboot-app.jar"]**
```




### Kubernetes


**Q) K8 commands you used?**
A) Common Kubernetes (k8s) commands include:

- `kubectl get pods` : List all pods in a namespace.
- `kubectl describe pod <pod-name>` : Describe a specific pod.
- `kubectl logs <pod-name>` : Fetch logs of a pod.
- `kubectl apply -f <file>` : Apply a configuration from a file.
- `kubectl delete pod <pod-name>` : Delete a pod.


**Q) How do you analyze logs of pods in your project?**
A) Logs of pods were analyzed using the `**kubectl logs**` command. For more comprehensive log management, we used centralized logging solutions like ELK stack (Elasticsearch, Logstash, and Kibana) or Fluentd with Elasticsearch and Kibana. Logs were collected, aggregated, and visualized to monitor application behavior and troubleshoot issues.



**Q) How would you troubleshoot and diagnose issues like pod crashes, failed deployments, or network connectivity problems in a Kubernetes cluster?**
A) Troubleshooting involves several steps:

- **Pod Crashes:** Check pod logs using `kubectl logs <pod-name>`  to identify errors. Use `kubectl describe pod <pod-name>`  to inspect events and resource issues.
- **Failed Deployments:** Check the status of the deployment with `kubectl get deployments`  and describe it using `kubectl describe deployment <deployment-name>` . Look for issues in configuration, resource limits, or image pull errors.
- **Network Connectivity Problems:** Use `kubectl exec -it <pod-name> -- /bin/bash`  to access the pod's shell and test network connectivity using tools like `curl`  or `ping` . Check network policies and service configurations.


**Q) Explain the difference between a Pod and a Container in Kubernetes.**
A) A Pod is the smallest deployable unit in Kubernetes, representing a single instance of a running process in the cluster. A Pod can contain one or more containers that share the same network namespace and storage. Containers within a Pod can communicate with each other using localhost and share storage volumes.



### CI/CD


**Q) What is the difference between CI and CD?**
A) Continuous Integration (CI) involves automatically building and testing code changes as they are committed to the version control repository.

Continuous Delivery (CD) extends CI by automatically deploying code changes to staging or production environments after passing automated tests, ensuring that the software is always in a deployable state.



**Q) Explain steps you used in CI/CD in your project.**
A) In our project, the CI/CD pipeline involved several steps:

- **Code Commit:** Developers commit code to the version control system (e.g., Git).
- **Build:** A CI tool (e.g., Jenkins) automatically triggers a build, compiling the code and running unit tests.
- **Test:** Automated tests (unit, integration, and functional) are executed to validate the code.
- **Package:** The application is packaged into a Docker container.
- **Deploy:** The container is deployed to staging environments for further testing.
- **Approval:** After passing tests, the code is manually or automatically approved for deployment to production.
- **Monitor:** Post-deployment, monitoring and alerting systems ensure the application runs smoothly.


### Cloud


**Q) Which cloud platform have you used and what services have you used?**
A) I have used AWS (Amazon Web Services) extensively. Key services used include:

- **EC2:** Virtual servers for running applications.
- **S3:** Object storage for storing files and backups.
- **RDS:** Managed relational databases.
- **Lambda:** Serverless computing for running code without provisioning servers.
- **EKS:** Managed Kubernetes service for container orchestration.
- **CloudWatch:** Monitoring and logging service.


### Alerts and Logging


**Q) What platform have you used to visualize logs for your application deployed?**
A) We used the ELK stack (Elasticsearch, Logstash, and Kibana) for log visualization. Logs from applications were aggregated and sent to Elasticsearch via Logstash, and Kibana was used to create dashboards and visualize the logs.

Alternatively, we also used tools like Grafana with Loki for log aggregation and visualization.



**Q) How do you alert yourself in case of downtime at prod application?**
A) We set up alerting mechanisms using monitoring tools like Prometheus with Alertmanager, Grafana, and CloudWatch Or can also be done through new relic.

Alerts were configured based on specific metrics and thresholds, such as response time, error rates, and resource utilization. Notifications were sent via email, Slack, teams or PagerDuty to ensure timely response and resolution of issues.





















**Q) What is prometheus and Grafana? How do they work with each other?**

**Prometheus** and **Grafana** are two widely used open-source tools for monitoring and observability. They are often used together to provide a comprehensive monitoring solution for applications, services, and infrastructure.

### Prometheus
Prometheus is a powerful monitoring and alerting toolkit designed specifically for reliability and scalability. It is part of the Cloud Native Computing Foundation (CNCF).

#### Key Features:
1. **Time-Series Database**: Prometheus stores all data as time series, with metrics identified by a metric name and key-value pairs called labels.
2. **Pull-Based Model**: Prometheus scrapes (pulls) metrics from configured targets at regular intervals.
3. **Multi-Dimensional Data Model**: Metrics can be sliced and diced along multiple dimensions, which allows for flexible querying and alerting.
4. **Powerful Query Language (PromQL)**: Prometheus has a robust query language that enables complex queries, calculations, and aggregations.
5. **Alerting**: Prometheus can trigger alerts based on queries, which can be routed to various notification channels via Alertmanager.
6. **Service Discovery**: Prometheus supports service discovery mechanisms to automatically find and monitor targets.
#### Use Cases:
- Monitoring infrastructure (servers, containers, etc.)
- Application performance monitoring
- Database monitoring
- Alerting on threshold breaches or anomalies
### Grafana
Grafana is an open-source analytics and monitoring platform that is often used in conjunction with Prometheus to visualize time-series data.

#### Key Features:
1. **Dashboards**: Grafana provides a rich set of visualization options (graphs, charts, tables, heatmaps, etc.) to create interactive and dynamic dashboards.
2. **Data Source Integration**: Grafana supports numerous data sources, including Prometheus, Elasticsearch, InfluxDB, MySQL, and many others.
3. **Custom Alerts**: Alerts can be configured within Grafana dashboards to notify users of specific conditions or thresholds.
4. **User Management**: Grafana supports user authentication and team-based access control, allowing for secure and collaborative dashboard management.
5. **Plugins**: A wide range of plugins is available to extend Grafana’s capabilities, including new data sources, panels, and applications.
#### Use Cases:
- Visualizing application metrics collected by Prometheus
- Creating operational dashboards for system and network monitoring
- Business intelligence and analytics
- Combining data from multiple sources into a single dashboard
### How They Work Together
1. **Data Collection**: Prometheus collects and stores metrics from various targets (e.g., application endpoints, exporters).
2. **Querying**: Grafana queries Prometheus to retrieve the stored metrics using PromQL.
3. **Visualization**: Grafana visualizes these metrics on customizable dashboards, enabling users to monitor the performance and health of their systems in real-time.
4. **Alerting**: Alerts configured in Prometheus can be visualized in Grafana dashboards, and additional alerts can be configured directly in Grafana.
### Example Workflow:
1. **Set Up Prometheus**: Configure Prometheus to scrape metrics from your application endpoints.
2. **Set Up Grafana**: Install Grafana and configure Prometheus as a data source.
3. **Create Dashboards**: Use Grafana to create dashboards that visualize the metrics collected by Prometheus.
4. **Configure Alerts**: Set up alerts in Prometheus and/or Grafana to notify you of critical issues.
   By using Prometheus for metric collection and Grafana for visualization, you can gain deep insights into your system's performance and reliability, enabling proactive management and faster troubleshooting of issues.









## What is Sharding in database?
Sharding in a database is a technique for splitting a large database into smaller, more manageable pieces called shards. These shards are then distributed across multiple servers or nodes. Here’s a breakdown of how it works:

- **Imagine a huge bookshelf:** This bookshelf represents your entire database, overflowing with books (data).
- **Sharding is like dividing the bookshelf:** You split the data into smaller sections based on a chosen criteria (like genre, author, publication date). Each section becomes a shard.
- **Distributing the shards:** Each shard is then placed on a separate server, like placing the categorized books on different shelves in different rooms.


## What is the difference between Spring Filter and Spring Interceptors?


## How JWT token works internally? (you should know the flow of it, and how the token is used internally).
A JSON Web Token (JWT) is a compact, URL-safe means of representing claims that can be transferred between two parties. The claims in a JWT are encoded as a JSON object that is used as the payload of a JSON Web Signature (JWS) structure or as the plaintext of a JSON Web Encryption (JWE) structure, enabling the claims to be digitally signed or integrity protected with a Message Authentication Code (MAC) and/or encrypted.

Here’s how JWT works internally:

1. The client sends a request to the server to authenticate a user.
2. The server verifies the user’s credentials and generates a JWT if the user is authenticated.
3. The server sends the JWT back to the client.
4. The client stores the JWT and includes it in the header of subsequent requests to protected routes on the server.
5. The server verifies the JWT and processes the request if the token is valid.
   A JWT consists of three parts: a header, a payload, and a signature.

1. The header typically consists of two parts: the type of the token, which is JWT, and the signing algorithm being used, such as HMAC SHA256 or RSA.
2. The second part of the token is the payload, which contains the claims. Claims are statements about an entity (typically, the user) and additional data. There are three types of claims: registered, public, and private claims.
3. The third part of the token is the signature, which is used to verify that the sender of the JWT is who it says it is and to ensure that the message wasn’t changed along the way.
   To create the signature part you have to take the encoded header, the encoded payload, a secret, the algorithm specified in the header, and sign that. For example, if you want to use the HMAC SHA256 algorithm, the signature will be created in the following way:

HMACSHA256( base64UrlEncode(header) + “.” + base64UrlEncode(payload), secret)

The complete JWT is then composed by concatenating the encoded header, the encoded payload, and the signature, with periods (.) separating them. For example:

xxxxx.yyyyy.zzzzz
















































































